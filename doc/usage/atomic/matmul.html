

<!DOCTYPE html>
<html class="writer-html4" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Matrix Multiply &mdash; OKKernel  documentation</title>
  

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> OKKernel
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../abstract.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../abstract.html#history">History</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../architecture.html">TPU Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture.html#memory-types">Memory Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture.html#heterogeneous-programming">Heterogeneous Programming</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../layout.html">Address of Tensor in Local Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layout.html#scatter-features-to-different-npus">Scatter Features to Different NPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layout.html#strides-in-local-memory">Strides in Local Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layout.html#strides-in-system-memory">Strides in System Memory</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layout.html#layouts">Layouts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../layout.html#storage-modes">Storage Modes</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../refined.html">About Function Names</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#some-definitions">Some Definitions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#common-functions">Common Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#utils-functions">Utils Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#gdma-functions">GDMA Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#memory-functions">Memory Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#data-type-converting-functions">Data Type Converting Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#fp32-binary-functions">FP32 Binary Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#bit-binary-functions">32-Bit Binary Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#fp32-unary-functions">FP32 Unary Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#fp32-neural-network-functions">FP32 Neural Network Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#fixed-point-binary-functions">Fixed Point Binary Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../refined.html#fixed-point-unary-functions">Fixed Point Unary Functions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../programming_device.html">Programming on Device</a></li>
<li class="toctree-l1"><a class="reference internal" href="../programming_host.html">Programming on Host</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../demo.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demo.html#compilation-tools">Compilation Tools</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demo.html#header-files-and-libraries">Header Files and Libraries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demo.html#develop">Develop</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demo.html#compile-and-update-firmware">Compile and Update Firmware</a></li>
<li class="toctree-l1"><a class="reference internal" href="../demo.html#execute">Execute</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">OKKernel</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Matrix Multiply</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/usage/atomic/matmul.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="matrix-multiply">
<h1>Matrix Multiply<a class="headerlink" href="#matrix-multiply" title="Permalink to this headline">¶</a></h1>
<p>由于在Local Memory中数据都是按照tensor的方式存储的，因此需要将2维矩阵拆分成4维的tensor形式。</p>
<p>假设矩阵有Y行X列，而tensor的几何尺寸为 NCHW，那么：</p>
<p>N = Y</p>
<p>C = (X + W - 1) / W</p>
<p>H = 1</p>
<p>W = W</p>
<p>也就是将矩阵的列分解到C和W两个维度，具体分配由用户决定，接口如下。</p>
<div class="section" id="id1">
<h2>浮点运算<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>浮点矩阵乘法运算，可以实现 Y = L * R + B 或者 Y = trans(L) * R + B。</p>
<blockquote>
<div><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="k">typedef</span> <span class="k">struct</span> <span class="p">{</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">input_l_addr</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">input_r_addr</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">bias_addr</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">output_addr</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">l_row</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">l_col</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">l_tensor_w</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">l_tensor_c</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">r_tensor_w</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">r_tensor_c</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">l_trans</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">using_bias</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">result_add</span><span class="p">;</span>
<span class="p">}</span> <span class="n">MatmulParam</span><span class="p">;</span>

<span class="kt">void</span> <span class="nf">bm_atomic_matmul</span><span class="p">(</span><span class="k">const</span> <span class="n">MatmulParam</span><span class="o">*</span> <span class="n">param</span><span class="p">);</span>
</pre></div>
</div>
</div></blockquote>
<p>参数说明：</p>
<ul class="simple">
<li>input_l_addr：存放左矩阵的Local Memory偏移地址;</li>
<li>input_r_addr：存放右矩阵的Local Memory偏移地址;</li>
<li>bias_addr：存放bias系数的Local Memory偏移地址;</li>
<li>output_addr：存放结果矩阵的Local Memory偏移地址;</li>
<li>l_row：左矩阵的行数;</li>
<li>l_col：左矩阵的列数;</li>
<li>l_tensor_w：左矩阵的列分解后，分配给W维度的大小;</li>
<li>l_tensor_c：左矩阵的列分解后，分配给C维度的大小;</li>
<li>r_tensor_w：右矩阵的列分解后，分配给W维度的大小;</li>
<li>r_tensor_c：右矩阵的列分解后，分配给C维度的大小;</li>
<li>l_trans： 左矩阵是否要进行转置操作</li>
<li>using_bias： 是否含有bias运算</li>
<li>result_add： 是否累加上原来的结果，也就是将本次矩阵乘法结果与output_addr本来存放的值进行累加;</li>
</ul>
</div>
<div class="section" id="id2">
<h2>定点运算<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>定点矩阵乘法运算，左矩阵、右矩阵均为8bit，bias为16bits，结果可以是8bits或者16bits，可以实现以下功能：</p>
<p>Y[7:0] = (L[7:0] * R[7:0] + B[15:0]) &gt;&gt; m</p>
<p>或者</p>
<p>Y[15:0] = (L[7:0] * R[7:0] + B[15:0]) &gt;&gt; m</p>
<p>或者</p>
<p>Y[7:0] = (L[7:0] * R[7:0] + B[15:0] + (Y[15:0] &lt;&lt; n)) &gt;&gt; m</p>
<p>或者</p>
<p>Y[15:0] = (L[7:0] * R[7:0] + B[15:0] + (Y[15:0] &lt;&lt; n)) &gt;&gt; m</p>
<p>所有输入输出均按照1N模式存储。</p>
<blockquote>
<div><div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="k">typedef</span> <span class="k">struct</span> <span class="p">{</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">input_l_addr</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">input_r_addr</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">bias_addr</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">output_addr</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">l_row</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">l_col</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">l_tensor_w</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">l_tensor_c</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">r_tensor_w</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">r_tensor_c</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">lshfit_bit</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">rshift_bit</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">l_trans</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">using_bias</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">result_add</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">result_add_sign</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">if_relu</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">input_l_sign</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">input_r_sign</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">bias_sign</span><span class="p">;</span>
    <span class="kt">bool</span> <span class="n">output_16bit</span><span class="p">;</span>
<span class="p">}</span> <span class="n">MatmulQuantParam</span><span class="p">;</span>

<span class="kt">void</span> <span class="nf">bm_atomic_matmul_quantized</span><span class="p">(</span><span class="k">const</span> <span class="n">MatmulQuantParam</span><span class="o">*</span> <span class="n">param</span><span class="p">);</span>
</pre></div>
</div>
</div></blockquote>
<p>参数说明：</p>
<ul class="simple">
<li>input_l_addr：存放左矩阵的Local Memory偏移地址;</li>
<li>input_r_addr：存放右矩阵的Local Memory偏移地址;</li>
<li>bias_addr：存放bias系数的Local Memory偏移地址;</li>
<li>output_addr：存放结果矩阵的Local Memory偏移地址;</li>
<li>l_row：左矩阵的行数;</li>
<li>l_col：左矩阵的列数;</li>
<li>l_tensor_w：左矩阵的列分解后，分配给W维度的大小;</li>
<li>l_tensor_c：左矩阵的列分解后，分配给C维度的大小;</li>
<li>r_tensor_w：右矩阵的列分解后，分配给W维度的大小;</li>
<li>r_tensor_c：右矩阵的列分解后，分配给C维度的大小;</li>
<li>lshift_bit： 如果result_add 为真，output_addr本来存放的值可以左移后与该矩阵乘法结果累加，该参数表示左移位数;</li>
<li>rshift_bit： add result之后的结果右移位数;</li>
<li>l_trans： 左矩阵是否要进行转置操作</li>
<li>using_bias： 是否含有bias运算</li>
<li>result_add： 是否累加上原来的结果，也就是将本次矩阵乘法结果与output_addr本来存放的值进行累加;</li>
<li>result_add_sign： 如果if_add_result为真，那么该参数表示Y_start_addr本来存放的值是否为有符号数;</li>
<li>if_relu： 是否对最终的结果做relu操作;</li>
<li>input_l_sign/input_r_sign/bias_sign：分别表示左矩阵、右矩阵以及bias的值是否为有符号数;</li>
<li>output_16bit： 输出结果是否为16bits。</li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2019, SOPHGO.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>